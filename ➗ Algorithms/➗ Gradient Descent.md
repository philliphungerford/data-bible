---
type: Algorithm
title: Gradient Descent
tags: []
---

# Gradient Descent

- Theory: Gradient Descent is an iterative optimization algorithm used to minimize a loss function.

- Steps: The algorithm updates the model parameters in the opposite direction of the gradient of the loss function.

- Variants: Stochastic Gradient Descent (SGD), Mini-Batch Gradient Descent.

- Applications: Used in various machine learning models such as linear regression, logistic regression, and neural networks.

